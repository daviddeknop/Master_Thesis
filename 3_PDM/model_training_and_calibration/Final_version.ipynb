{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final calibration of PDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.4/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.5.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.4/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='54cd2ef4-38bb-4c47-a735-f597cac7fc4c'>\n",
       "  <div id=\"b3316786-837a-4bed-a71a-e03744d78ffd\" data-root-id=\"54cd2ef4-38bb-4c47-a735-f597cac7fc4c\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"720252a8-cc10-48c1-b733-b4b609466ef1\":{\"version\":\"3.5.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"54cd2ef4-38bb-4c47-a735-f597cac7fc4c\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"124e7283-0d2c-45cb-b9da-4475e45084f0\",\"attributes\":{\"plot_id\":\"54cd2ef4-38bb-4c47-a735-f597cac7fc4c\",\"comm_id\":\"e14352fa6f3740968f7221d9da350aa4\",\"client_comm_id\":\"963eae778e404beb993b7242c7c1b1cf\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"720252a8-cc10-48c1-b733-b4b609466ef1\",\"roots\":{\"54cd2ef4-38bb-4c47-a735-f597cac7fc4c\":\"b3316786-837a-4bed-a71a-e03744d78ffd\"},\"root_ids\":[\"54cd2ef4-38bb-4c47-a735-f597cac7fc4c\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "54cd2ef4-38bb-4c47-a735-f597cac7fc4c"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import warnings\n",
    "import pyswarms as ps\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pad = Path(os.getcwd())\n",
    "if pad.name == \"model_training_and_calibration\":\n",
    "    pad_correct = pad.parent\n",
    "    os.chdir(pad_correct)\n",
    "from functions.PDM import (PDM, parameter_sampling, \n",
    "                           Nelder_Mead_calibration,PDM_calibration_wrapper_PSO)\n",
    "from functions.performance_metrics import NSE, mNSE, FHV, NSE_LF\n",
    "from functions.plotting_functions import plot_FDC\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore', category= RuntimeWarning)\n",
    "warnings.filterwarnings(action = 'ignore', category= UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and process initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters_initial = pd.DataFrame({\n",
    "    'cmax': 944.6,\n",
    "    'cmin':59.8,\n",
    "    'b':0.51,\n",
    "    'be':1.5,\n",
    "    'k1':14.7,\n",
    "    'k2':4.2,\n",
    "    'kb':175.5,\n",
    "    'kg':10265,\n",
    "    'St': 25.3,\n",
    "    'bg':1.00000,\n",
    "    'tdly': 12.00000,\n",
    "    'qconst':-0.13,\n",
    "}, dtype = np.float32, index =[0])\n",
    "display(parameters_initial)\n",
    "\n",
    "\n",
    "\n",
    "zwalm_shape = gpd.read_file('data/Zwalm_shape/zwalm_shapefile_david_4326.shp')\n",
    "area_zwalm_new = np.single(zwalm_shape.OPPERVL[0]/10**6)\n",
    "print('Area of the Zwalm by shapefile: ' + str(area_zwalm_new) + '[km^2]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the bounds of the parameters as described in thesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lower_bound = np.array([160,0,0.1,1,0.9,0.1,0,700,0,1,0,-0.3]) \n",
    "upper_bound = np.array([5000,300,2,2,40,15,5000,25000,150,1.000000000000001,24,0.03])\n",
    "bounds_list = []\n",
    "for i in range(len(lower_bound)):\n",
    "    bounds_list.append((lower_bound[i],upper_bound[i]))\n",
    "#bounds_opt = tuple(bounds_list)\n",
    "bounds_opt = bounds_list\n",
    "print(bounds_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bounds_dict = {}\n",
    "for i in range(len(bounds_opt)):\n",
    "    bounds_dict[parameters_initial.columns.values[i]] = bounds_opt[i]\n",
    "bounds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_output_folder = Path('data/Zwalm_data/preprocess_output')\n",
    "p_ep_zwalm = pd.read_pickle(preprocess_output_folder/'Final_Forcings_PDM.pkl')\n",
    "\n",
    "\n",
    "Q_output_folder = Path(\"data/Zwalm_data/output_Q\")\n",
    "Q_day = pd.read_pickle(Q_output_folder/\"Q_data.pkl\")\n",
    "\n",
    "Q_day = Q_day.set_index('Timestamp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warmup_months = 12\n",
    "start_p1 = p_ep_zwalm['Timestamp'].iloc[0]\n",
    "start_endofwarmup_p1 = start_p1 + relativedelta(months = warmup_months)\n",
    "end_p1 =  pd.Timestamp(datetime(year = 2017, month = 12, day = 14, hour = 23))\n",
    "\n",
    "print('Characteristics of period 1: start = '  + str(start_p1) + ', start of post warmup = ' + str(start_endofwarmup_p1) + ' and end = ' + str(end_p1))\n",
    "\n",
    "start_p2 = pd.Timestamp(datetime(year = 2017, month= 12, day = 15, hour = 0))\n",
    "start_endofwarmup_p2 = start_p2 + relativedelta(months = warmup_months)\n",
    "end_p2 = p_ep_zwalm['Timestamp'].iloc[-1]\n",
    "print('Characteristics of period 2: start = '  + str(start_p2) + ', start of post warmup = ' + str(start_endofwarmup_p2) + ' and end = ' + str(end_p2))\n",
    "\n",
    "p1_period_excl_warmup = pd.date_range(start_endofwarmup_p1,end_p1,\n",
    "freq = 'D') #used for scoring the model \n",
    "p1_period = pd.date_range(start_p1, end_p1, freq = 'H')\n",
    "p2_period_excl_warmup = pd.date_range(start_endofwarmup_p2,end_p2,\n",
    "freq = 'D') #used for scoring the model \n",
    "p2_period = pd.date_range(start_p2, end_p2, freq = 'H')\n",
    "p_all_nowarmup = pd.date_range(start_endofwarmup_p1, end_p2)\n",
    "p_all = pd.date_range(start_p1, end_p2)\n",
    "\n",
    "#now subdivide ep data on p1 and p2\n",
    "#for ease of selecting data, set time as index!\n",
    "#select forcings for p1 period\n",
    "p_zwalm_p1 = p_ep_zwalm.set_index('Timestamp').loc[p1_period]\n",
    "#select forcings for p2 period\n",
    "p_zwalm_p2 = p_ep_zwalm.set_index('Timestamp').loc[p2_period]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check initial performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltat = np.single(1) #internal resolution =  1 hour\n",
    "deltat_out = np.single(24) #output resolution = 24 hour\n",
    "pd_zwalm_out_initial = PDM(P = p_ep_zwalm['total_precipitation_sum'].values, \n",
    "    EP = p_ep_zwalm['potential_evaporation_sum'].values,\n",
    "    t = p_ep_zwalm['Timestamp'].values,\n",
    "    area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,\n",
    "    parameters = parameters_initial)\n",
    "pd_zwalm_out_initial = pd_zwalm_out_initial.set_index(['Time'])\n",
    "pd_zwalm_out_initial_p2 = pd_zwalm_out_initial[start_p2:end_p2] #no warmup!\n",
    "pd_zwalm_out_initial_p1 = pd_zwalm_out_initial[start_endofwarmup_p1:end_p1]\n",
    "\n",
    "kwargs_p1 = {'Qmod':pd_zwalm_out_initial_p1['qmodm3s'].values, 'Qobs':Q_day.loc[start_endofwarmup_p1:end_p1,'streamflow'].values}\n",
    "kwargs_p2 = {'Qmod':pd_zwalm_out_initial_p2['qmodm3s'].values, 'Qobs':Q_day.loc[start_p2:end_p2,'streamflow'].values}\n",
    "kwargs_full = {'Qmod':pd_zwalm_out_initial.loc[start_endofwarmup_p1:end_p2,'qmodm3s'].values, 'Qobs':Q_day.loc[start_endofwarmup_p1:end_p2,'streamflow'].values}\n",
    "# check (m)NSE and FHV\n",
    "\n",
    "nse_initial_p2 = NSE(**kwargs_p2)\n",
    "mnse_initial_p2 = mNSE(**kwargs_p2)\n",
    "FHV_initial_p2 = FHV(**kwargs_p2)\n",
    "print('NSE on p2 for initial set:' + str(nse_initial_p2))\n",
    "print('mNSE on p2 for initial set:' + str(mnse_initial_p2))\n",
    "print('FHV on p2 for initial set: ' + str(FHV_initial_p2) + '%')\n",
    "\n",
    "nse_initial_p1 = NSE(**kwargs_p1)\n",
    "mnse_initial_p1 = mNSE(**kwargs_p1)\n",
    "FHV_initial_p1 = FHV(**kwargs_p1)\n",
    "print('NSE on p1 for initial set:' + str(nse_initial_p1))\n",
    "print('mNSE on p1 for initial set:' + str(mnse_initial_p1))\n",
    "print('FHV on p1 for initial set: ' + str(FHV_initial_p1) + '%')\n",
    "\n",
    "nse_initial = NSE(**kwargs_full)\n",
    "mnse_initial = mNSE(**kwargs_full)\n",
    "FHV_initial = FHV(**kwargs_full)\n",
    "print('NSE for initial set:' + str(nse_initial))\n",
    "print('mNSE for initial set:' + str(mnse_initial))\n",
    "print('FHV for for initial set: ' + str(FHV_initial) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd_zwalm_out_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize = (10,6))\n",
    "plot = Q_day['streamflow'].hvplot(alpha = 0.7, label = 'observed') * pd_zwalm_out_initial['qmodm3s'].hvplot(\n",
    "    alpha = 0.7, frame_width = 900, frame_height = 400,label = 'modelled', line_dash = 'dashed') \n",
    "plot.opts(\n",
    "    xlabel='Time',\n",
    "    ylabel='Streamflow (m³/s)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.style.use('seaborn-v0_8-colorblind')\n",
    "plt.style.use('default')\n",
    "fig, ax = plt.subplots(figsize = (9,5), constrained_layout = True)\n",
    "Q_day['streamflow'].plot(alpha = 0.7, label = '$Q_o$',ax = ax)\n",
    "pd_zwalm_out_initial['qmodm3s'].plot(\n",
    "    alpha = 0.7, label = '$Q_{m,init}$', linestyle = '--', ax = ax\n",
    ")\n",
    "ax.set_ylabel('$Q$ [m$^3$/s]')\n",
    "ax.set_xlabel('Time')\n",
    "ax2 = ax.twinx()\n",
    "p_zwalm_t = p_ep_zwalm.set_index('Timestamp')\n",
    "ax2.plot(p_zwalm_t.index, p_zwalm_t['total_precipitation_sum'],c = 'grey')\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_ylim(3*np.max(p_zwalm_t['total_precipitation_sum']),0)\n",
    "ax2.set_ylabel('$P$ [mm/h]')\n",
    "# p_zwalm_t['P_thiessen'].plot(ax = ax2, alpha = 0.1)\n",
    "# box = ax.get_position()\n",
    "# ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "pad = Path('Figures/Figures_chapter_PDM')\n",
    "if not os.path.exists(pad):\n",
    "    os.makedirs(pad)\n",
    "fig.savefig(pad/'Q_initial_set.pdf', format = 'pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig, ax = plot_FDC(Q_day['streamflow'].values, label = '$Q_o$', fig = fig, ax = ax, cutoff_bool=False)\n",
    "fig, ax = plot_FDC(pd_zwalm_out_initial['qmodm3s'].values, fig = fig, ax = ax, label = '$Q_{m,init}$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nelder-Mead Calibration: starting from multiple initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = parameters_initial.columns.to_list()\n",
    "n_paramsets = 50\n",
    "pd_init_params = parameter_sampling(names, bounds_opt, n_paramsets)\n",
    "pd_init_params.head()\n",
    "pd_opt_params = parameters_initial.copy()\n",
    "col_names_perf = ['NSE_cal','NSE_val','NSE_full','mNSE_cal','mNSE_val','mNSE_full']\n",
    "#empyt dataframe for parameters and performance\n",
    "append = 1\n",
    "if append:\n",
    "    pd_perf = pd.read_csv('data/Zwalm_PDM_parameters/NM_NSE_performances_50.csv')\n",
    "    pd_opt_params = pd.read_csv('data/Zwalm_PDM_parameters/NM_NSE_parameters_50.csv')\n",
    "    start = pd_opt_params.shape[0]\n",
    "else:\n",
    "    pd_perf = pd.DataFrame(columns = col_names_perf)\n",
    "    pd_opt_params = pd.DataFrame(columns = names)\n",
    "    start = 0\n",
    "display(pd_perf.head())\n",
    "display(pd_opt_params.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifications for calibration \n",
    "performance_metric = 'NSE'\n",
    "P_np = p_zwalm_p1['total_precipitation_sum'].values\n",
    "EP_np = p_zwalm_p1['potential_evaporation_sum'].values\n",
    "deltat = np.single(1)\n",
    "deltatout = np.single(24)\n",
    "t_model = p1_period.values\n",
    "t_calibration = p1_period_excl_warmup.values\n",
    "Qobs = Q_day['streamflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/Zwalm_PDM_parameters'):\n",
    "    os.mkdir('data/Zwalm_PDM_parameters')\n",
    "\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_keepawake(keep_screen_awake=True)\n",
    "exec_optimisation = True\n",
    "if exec_optimisation:\n",
    "        print('test')\n",
    "        for i in np.arange(start, n_paramsets):\n",
    "                # Optimize parametersets with NM\n",
    "                pd_init_temp = pd_init_params.iloc[i,:]\n",
    "                opt_out_NSE = Nelder_Mead_calibration(\n",
    "                        pd_init_temp.values, parameters_initial.columns, bounds_opt, performance_metric, P_np, EP_np,\n",
    "                        area_zwalm_new, deltat, deltatout, t_model, t_calibration, Qobs  \n",
    "                )\n",
    "                ## Assign optimized parameter sets\n",
    "                pd_temp = pd.DataFrame(opt_out_NSE.x.reshape(1,-1), columns = names)\n",
    "                pd_opt_params = pd.concat([pd_opt_params, pd_temp], axis = 0, ignore_index=True)\n",
    "                \n",
    "                ## Quantify performance of parameter sets \n",
    "                pd_zwalm_out = PDM(P = p_ep_zwalm['total_precipitation_sum'].values, \n",
    "                        EP = p_ep_zwalm['potential_evaporation_sum'].values, t = p_ep_zwalm['Timestamp'].values,\n",
    "                        area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,parameters = pd_temp\n",
    "                )\n",
    "                pd_zwalm_out = pd_zwalm_out.set_index('Time')\n",
    "                mnse_cal = mNSE(\n",
    "                        pd_zwalm_out.loc[start_endofwarmup_p1:end_p1,'qmodm3s'].values,\n",
    "                        Q_day.loc[start_endofwarmup_p1:end_p1,'streamflow'].values\n",
    "                )\n",
    "                nse_cal = NSE(\n",
    "                        pd_zwalm_out.loc[start_endofwarmup_p1:end_p1,'qmodm3s'].values,\n",
    "                        Q_day.loc[start_endofwarmup_p1:end_p1,'streamflow'].values\n",
    "                )\n",
    "                mnse_val = mNSE(\n",
    "                        pd_zwalm_out.loc[start_p2:end_p2,'qmodm3s'].values,\n",
    "                        Q_day.loc[start_p2:end_p2,'streamflow'].values\n",
    "                )\n",
    "                nse_val= NSE(\n",
    "                        pd_zwalm_out.loc[start_p2:end_p2,'qmodm3s'].values,\n",
    "                        Q_day.loc[start_p2:end_p2,'streamflow'].values\n",
    "                ) #mistake was made here (mNSE was used) => wrong data in dataframe\n",
    "                mnse_full = mNSE(\n",
    "                        pd_zwalm_out.loc[start_endofwarmup_p1:end_p2,'qmodm3s'].values,\n",
    "                        Q_day.loc[start_endofwarmup_p1:end_p2,'streamflow'].values\n",
    "                )\n",
    "                nse_full = NSE(\n",
    "                        pd_zwalm_out.loc[start_endofwarmup_p1:end_p2,'qmodm3s'].values,\n",
    "                        Q_day.loc[start_endofwarmup_p1:end_p2,'streamflow'].values\n",
    "                )\n",
    "                pd_temp_perf = pd.DataFrame(np.array([nse_cal, nse_val, nse_full, mnse_cal, mnse_val, mnse_full]).reshape(1,-1), columns= col_names_perf, index = [i])\n",
    "                pd_perf = pd.concat([pd_perf, pd_temp_perf], axis=0, ignore_index = True)\n",
    "\n",
    "                ## Write out\n",
    "                pd_opt_params.to_csv('data/Zwalm_PDM_parameters/NM_NSE_parameters_50.csv', mode = 'w', index = False)\n",
    "                pd_perf.to_csv('data/Zwalm_PDM_parameters/NM_NSE_performances_50.csv', mode = 'w', index = False)\n",
    "                print('dataset ' + str(i) + ' out of '  + str(n_paramsets) + ' has been calibrated')\n",
    "#unset_keepawake()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess calibration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Get current working directory and its parent\n",
    "pad = Path(os.getcwd())\n",
    "parent = pad.parent\n",
    "performance_file = parent / 'data' /'Zwalm_PDM_parameters' / 'NM_NSE_performances_50.csv'\n",
    "parameters_file = parent / 'data' /'Zwalm_PDM_parameters' / 'NM_NSE_parameters_50.csv'\n",
    "\n",
    "# Read the performance file and find the row with the highest NSE_cal\n",
    "performances = pd.read_csv(performance_file)\n",
    "best_row_index = performances['NSE_val'].idxmax()  # Index of the best NSE_cal\n",
    "best_performance_row = performances.iloc[best_row_index]\n",
    "print(best_performance_row)\n",
    "\n",
    "# Read the parameters file and select the corresponding row\n",
    "parameters = pd.read_csv(parameters_file)\n",
    "best_parameters_row = parameters.iloc[best_row_index]\n",
    "\n",
    "# Format best_par to match the structure of parameters_initial\n",
    "best_par = pd.DataFrame({\n",
    "    'cmax': [best_parameters_row['cmax']],\n",
    "    'cmin': [best_parameters_row['cmin']],\n",
    "    'b': [best_parameters_row['b']],\n",
    "    'be': [best_parameters_row['be']],\n",
    "    'k1': [best_parameters_row['k1']],\n",
    "    'k2': [best_parameters_row['k2']],\n",
    "    'kb': [best_parameters_row['kb']],\n",
    "    'kg': [best_parameters_row['kg']],\n",
    "    'St': [best_parameters_row['St']],\n",
    "    'bg': [best_parameters_row['bg']],\n",
    "    'tdly': [best_parameters_row['tdly']],\n",
    "    'qconst': [best_parameters_row['qconst']],\n",
    "}, dtype=np.float32, index=[0])\n",
    "\n",
    "# Display the result\n",
    "print(\"Best Parameters:\")\n",
    "display(best_par)\n",
    "\n",
    "pd_zwalm_out = PDM(P = p_ep_zwalm['total_precipitation_sum'].values, \n",
    "    EP = p_ep_zwalm['potential_evaporation_sum'].values,\n",
    "    t = p_ep_zwalm['Timestamp'].values,\n",
    "    area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,\n",
    "    parameters = best_par)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd_zwalm_out.set_index('Time', inplace=True)\n",
    "\n",
    "# Filter data between 15/12/2017 and 31/12/2022\n",
    "start_date = '2017-12-15'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "filtered_pd_zwalm_out = pd_zwalm_out.loc[start_date:end_date]\n",
    "filtered_Q_day = Q_day.loc[start_date:end_date]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6.3, 3.5))\n",
    "\n",
    "# Plot observed streamflow\n",
    "plt.plot(filtered_Q_day.index, filtered_Q_day['streamflow'], label='Observed Discharge', color='blue', linewidth=1)\n",
    "\n",
    "# Plot simulated streamflow\n",
    "plt.plot(filtered_pd_zwalm_out.index, filtered_pd_zwalm_out['qmodm3s'], label='Simulated Discharge', color='red', linewidth = 1)\n",
    "plotvoor1param = filtered_pd_zwalm_out['qmodm3s']\n",
    "# Add axis labels and styling\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Discharge (m³/s)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(frameon=True, edgecolor='black')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pd_zwalm_out[['qmodm3s']].to_csv('qmodm3s_output.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_opt_params.columns)\n",
    "print(pd_opt_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate the results with the parametersets (as doubts about the values saved during calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pd_opt_params.iloc[0,:].values.reshape(1,-1), columns = pd_opt_params.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_names_list = [\n",
    "    'NSE_cal', 'NSE_val', 'NSE_full',\n",
    "    'mNSE_cal', 'mNSE_val', 'mNSE_full',\n",
    "    'FHV_cal', 'FHV_val', 'FHV_full',\n",
    "    'NSE_lf_cal', 'NSE_lf_val', 'NSE_lf_full'\n",
    "]\n",
    "print(metrics_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_param_sets = pd_opt_params.shape[0]\n",
    "pd_perf_recalc = pd.DataFrame(columns=metrics_names_list, \n",
    "                              index=range(0, n_param_sets))\n",
    "pd_list = []\n",
    "\n",
    "for i in range(n_param_sets):\n",
    "    pd_temp = pd.DataFrame(pd_opt_params.iloc[i, :].values.reshape(1, -1), columns=pd_opt_params.columns)\n",
    "    \n",
    "    pd_zwalm_out = PDM(\n",
    "        P=p_ep_zwalm['total_precipitation_sum'].values, \n",
    "        EP=p_ep_zwalm['potential_evaporation_sum'].values, \n",
    "        t=p_ep_zwalm['Timestamp'].values,\n",
    "        area=area_zwalm_new, deltat=deltat, deltatout=deltat_out,\n",
    "        parameters=pd_temp\n",
    "    )\n",
    "    \n",
    "    pd_zwalm_out = pd_zwalm_out.set_index('Time')\n",
    "    \n",
    "    pd_zwalm_out_p2 = pd_zwalm_out[start_p2:end_p2]  # no warmup!\n",
    "    pd_zwalm_out_p1 = pd_zwalm_out[start_endofwarmup_p1:end_p1]\n",
    "    \n",
    "    kwargs_p1 = {'Qmod': pd_zwalm_out_p1['qmodm3s'].values, 'Qobs': Q_day.loc[start_endofwarmup_p1:end_p1, 'streamflow'].values}\n",
    "    kwargs_p2 = {'Qmod': pd_zwalm_out_p2['qmodm3s'].values, 'Qobs': Q_day.loc[start_p2:end_p2, 'streamflow'].values}\n",
    "    kwargs_full = {'Qmod': pd_zwalm_out.loc[start_endofwarmup_p1:end_p2, 'qmodm3s'].values, 'Qobs': Q_day.loc[start_endofwarmup_p1:end_p2, 'streamflow'].values}\n",
    "\n",
    "    # Calibration metrics\n",
    "    mnse_cal = mNSE(**kwargs_p1)\n",
    "    nse_cal = NSE(**kwargs_p1)\n",
    "    fhv_cal = FHV(**kwargs_p1)\n",
    "    nse_lf_cal = NSE_LF(**kwargs_p1)\n",
    "\n",
    "    # Validation metrics\n",
    "    mnse_val = mNSE(**kwargs_p2)\n",
    "    nse_val = NSE(**kwargs_p2)\n",
    "    fhv_val = FHV(**kwargs_p2)\n",
    "    nse_lf_val = NSE_LF(**kwargs_p2)\n",
    "\n",
    "    # Full metrics\n",
    "    mnse_full = mNSE(**kwargs_full)\n",
    "    nse_full = NSE(**kwargs_full)\n",
    "    fhv_full = FHV(**kwargs_full)\n",
    "    nse_lf_full = NSE_LF(**kwargs_full)\n",
    "\n",
    "    # Insert results\n",
    "    pd_perf_recalc.iloc[i, :] = [\n",
    "        nse_cal, nse_val, nse_full,\n",
    "        mnse_cal, mnse_val, mnse_full,\n",
    "        fhv_cal, fhv_val, fhv_full,\n",
    "        nse_lf_cal, nse_lf_val, nse_lf_full\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_perf_recalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "x = pd_perf_recalc['NSE_val']\n",
    "y = pd_perf_recalc['NSE_lf_val']\n",
    "\n",
    "# Identify the point with the highest NSE_val\n",
    "highest_nse_index = pd_perf_recalc['NSE_val'].astype(float).idxmax()\n",
    "highest_nse_point = pd_perf_recalc.loc[highest_nse_index]\n",
    "\n",
    "print(highest_nse_index)\n",
    "print(highest_nse_point)\n",
    "\n",
    "# Separate points into green and red based on NSE_LF value\n",
    "pd_perf_recalc['Color'] = np.where(pd_perf_recalc['NSE_lf_val'] < highest_nse_point['NSE_lf_val'], 'red', 'green')\n",
    "\n",
    "# Count green and red points (excluding the highest NSE point from green)\n",
    "green_count = (pd_perf_recalc['Color'] == 'green').sum() - 1\n",
    "red_count = (pd_perf_recalc['Color'] == 'red').sum()\n",
    "\n",
    "# Filter out points below y = -1\n",
    "visible_df = pd_perf_recalc[pd_perf_recalc['NSE_lf_val'] >= -1]\n",
    "excluded_count = (pd_perf_recalc['NSE_lf_val'] < -1).sum()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(6.3, 3.5))\n",
    "for color, group in visible_df.groupby('Color'):\n",
    "    label = 'Better $\\mathrm{NSE}_{\\mathrm{LF}}$' if color == 'green' else 'Worse $\\mathrm{NSE}_{\\mathrm{LF}}$'\n",
    "    plt.scatter(group['NSE_val'], group['NSE_lf_val'], label=f\"{label}\", \n",
    "                color=color, alpha=0.7, edgecolor='k', s=50)\n",
    "\n",
    "# Highlight the point with the highest NSE_val, if it's visible\n",
    "if highest_nse_point['NSE_lf_val'] >= -1:\n",
    "    plt.scatter(highest_nse_point['NSE_val'], highest_nse_point['NSE_lf_val'], \n",
    "                color='blue', edgecolor='black', s=50, label='$\\mathrm{NSE}_{\\mathrm{LF}}$ of Highest NSE')\n",
    "\n",
    "plt.xlabel('NSE in Validation Period', fontsize=12)\n",
    "plt.ylabel('$\\mathrm{NSE}_{\\mathrm{LF}}$ in Validation Period', fontsize=12)\n",
    "plt.ylim(bottom=-1)  # Set Y-axis lower limit\n",
    "plt.ylim(top=1.1)  # Set Y-axis lower limit\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize = 9, frameon=True, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45, fontsize = 10)\n",
    "plt.yticks(fontsize = 10)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.axhline(y=1, color='black', linewidth=3)\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "plt.xticks(np.arange(0, 0.5, 0.1))\n",
    "plt.savefig(\"NSE_LF_PDM.png\", dpi=1000, bbox_inches='tight') \n",
    "plt.show()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Green count:\", green_count)\n",
    "print(\"Red count:\", red_count)\n",
    "print(\"Points not plotted (NSE_LF_val < -1):\", excluded_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,3, constrained_layout = True, figsize = (7,7))\n",
    "iter = 0\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        axes[i,j].scatter(x = pd_opt_params.iloc[:,iter], y = pd_perf_recalc['NSE_cal'], edgecolor = 'k')\n",
    "        axes[i,j].set_xlabel(pd_opt_params.columns[iter])\n",
    "        iter = iter + 1\n",
    "fig.suptitle('NSE on calibration set')\n",
    "fig.supylabel('NSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_opt_params.iloc[:,0])\n",
    "print(pd_perf['NSE_val'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same Figure but now limit the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,3, constrained_layout = True, figsize = (7,7))\n",
    "iter = 0\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        axes[i,j].scatter(x = pd_opt_params.iloc[:,iter], y = pd_perf['NSE_cal'], edgecolor = 'k')\n",
    "        axes[i,j].set_xlabel(pd_opt_params.columns[iter])\n",
    "        #axes[i,j].set_ylabel('NSE')\n",
    "        axes[i,j].set_ylim(0, pd_perf['NSE_cal'].max()+0.05)\n",
    "        iter = iter + 1\n",
    "fig.suptitle('NSE on calibration set')\n",
    "fig.supylabel('NSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict with names in math font\n",
    "names_dict = {'cmax':'$c_{max}$','cmin':'$c_{min}$','b':'$b$','be':'$b_e$','k1':'$k_1$','k2':'$k_2$','kb':'$k_b$','kg':'$k_g$','St':'$S_t$','bg':'$b_g$','tdly':'$t_d$','qconst':'$Q_c$'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_opt_params_plot = pd_opt_params.drop('bg',axis = 1)\n",
    "print(pd_opt_params)\n",
    "fig, axes = plt.subplots(4,3, constrained_layout = True, figsize = (7,7))\n",
    "iter = 0\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        if iter < pd_opt_params_plot.shape[1]:\n",
    "            axes[i,j].scatter(x = pd_opt_params_plot.iloc[:,iter], y = pd_perf_recalc['NSE_full'], edgecolor = 'k')\n",
    "            param_name = pd_opt_params_plot.columns[iter]\n",
    "            axes[i,j].set_xlabel(names_dict[param_name])\n",
    "            left_bound = bounds_dict[param_name][0]\n",
    "            right_bound = bounds_dict[param_name][1]\n",
    "            buffer = 0.05*(right_bound - left_bound)\n",
    "            axes[i,j].set_xlim(left_bound-buffer, right_bound+buffer)\n",
    "            axes[i,j].set_ylim(0.5, pd_perf['NSE_cal'].max()+0.05)\n",
    "            iter = iter + 1\n",
    "        else:\n",
    "            fig.delaxes(axes[i,j]) #delete empty subplot!\n",
    "#fig.suptitle('NSE on full set')\n",
    "fig.supylabel('NSE')\n",
    "fig.savefig('Figures/Figures_chapter_PDM/dottyplot_nsefull.pdf',format = 'pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Count number of parmaetersets with NSE below 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(pd_perf_recalc['NSE_full'] < 0.5))\n",
    "print(sum(pd_perf_recalc['NSE_full'] < 0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems acceptable to skip the few very bad perforer with NSE below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_perf_recalc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: determine best dataset based on best NSE and mNSE value for validation set. (paper on mNSE https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/1998WR900018). Goal = highest weighted sum. Update: Adapted to just best NSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_NSE_val = pd_perf_recalc.sort_values('NSE_val', ascending=False)\n",
    "# sorted_NSE_val['NSE_val_score'] = np.arange(1,51)\n",
    "# sorted_mNSE_val = sorted_NSE_val.sort_values('mNSE_val',ascending=False)\n",
    "# sorted_mNSE_val['mNSE_val_score'] = np.arange(1,51)\n",
    "# sorted_NSE_full = sorted_mNSE_val.sort_values('NSE_full',ascending=False)\n",
    "# sorted_NSE_full['NSE_full_score'] = np.arange(1,51)\n",
    "# sorted_NSE_full['total_score'] = sorted_NSE_full['mNSE_val_score'] + sorted_NSE_full['NSE_val_score']\n",
    "# sorted_total_score_val = sorted_NSE_full.sort_values('total_score')\n",
    "#sorted_total_score_val.head(10)\n",
    "sorted_NSE_val['score'] = sorted_NSE_val['NSE_val']\n",
    "sorted_score = sorted_NSE_val.sort_values('score',ascending=False)\n",
    "sorted_score.head(15)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the best dataset according to validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_best_param_set = sorted_score.iloc[0,:].name\n",
    "print('original index of best parameter set: ' + str(index_best_param_set))\n",
    "best_param_set = pd_opt_params.iloc[index_best_param_set,:]\n",
    "display(best_param_set)\n",
    "pd_zwalm_out_opt = PDM(P = p_ep_zwalm['total_precipitation_sum'].values, \n",
    "    EP = p_ep_zwalm['potential_evaporation_sum'].values,\n",
    "    t = p_ep_zwalm['Timestamp'].values,\n",
    "    area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,\n",
    "    parameters = pd.DataFrame(best_param_set.to_dict(),index=[0]))\n",
    "pd_zwalm_out_opt = pd_zwalm_out_opt.set_index('Time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the NSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_full_opt = NSE(\n",
    "        pd_zwalm_out_opt.loc[start_endofwarmup_p1:end_p2,'qmodm3s'].values,\n",
    "        Q_day.loc[start_endofwarmup_p1:end_p2,'streamflow'].values\n",
    ")\n",
    "print('Caculated NSE on full set: ' + str(nse_full_opt) )\n",
    "print('NSE as obtained during the calibration exercise :' + str(pd_perf.loc[index_best_param_set,'NSE_full']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_perf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvplot.extension('bokeh')\n",
    "Q_day['streamflow'].hvplot(alpha = 0.7, label = 'observed', line_width = 1.5) * pd_zwalm_out_initial['qmodm3s'].hvplot(\n",
    "    alpha = 0.7, frame_width = 900, frame_height = 400,label = 'Modelled: initial',line_dash = 'dashed',line_width = 1.5) * pd_zwalm_out_opt['qmodm3s'].hvplot(\n",
    "    alpha = 0.7,label = 'Modelled: optimised', line_dash = 'dashed', line_width = 1.5, color = 'green')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Q_day['streamflow'])\n",
    "print(pd_zwalm_out_opt['qmodm3s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Q_day['streamflow'],pd_zwalm_out_opt['qmodm3s'], label = 'optimised parameterset',alpha = 0.5)\n",
    "ax.scatter(Q_day['streamflow'],pd_zwalm_out_initial['qmodm3s'], label = 'initial parameterset',alpha = 0.5)\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QQ-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(pd_zwalm_out_initial)\n",
    "quantiles = np.linspace(0, 1, length)\n",
    "# obs_quan = np.quantile(Q_day['Value'].dropna(),quantiles)\n",
    "# mod_opt_quan = np.quantile(pd_zwalm_out_opt['qmodm3s'],quantiles, method = 'inverted_cdf')\n",
    "# mod_init_quan = np.quantile(pd_zwalm_out_initial['qmodm3s'],quantiles, method = 'inverted_cdf')\n",
    "\n",
    "nan_bool = Q_day['streamflow'].isna()\n",
    "obs_quan = np.sort(Q_day['streamflow'].dropna())\n",
    "mod_opt_quan = np.sort(pd_zwalm_out_opt['qmodm3s'][~nan_bool])\n",
    "mod_init_quan = np.sort(pd_zwalm_out_initial['qmodm3s'][~nan_bool])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(obs_quan, mod_opt_quan,marker = 'o',label = 'Optimised')\n",
    "ax.plot(obs_quan, mod_init_quan, marker = 'o', label = 'Initial')\n",
    "ax.plot(obs_quan, obs_quan, label = 'Ideal')\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$Q_{obs}$ [m$^3$/s]')\n",
    "ax.set_ylabel(r'$Q_{mod}$ [m$^3$/s]')\n",
    "ax.set_title('QQ-plot')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nan_bool)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 best NM parametersets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the 5 best according to validation dataset score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_dict_test = {}\n",
    "Cstar_nm_dict = {}\n",
    "top_nr = 50\n",
    "for i in range(top_nr):\n",
    "    index_temp = sorted_score.iloc[i,:].name\n",
    "    param_set_temp = pd.DataFrame(pd_opt_params.iloc[index_temp,:].to_dict(), index = [0])\n",
    "    pd_zwalm_out_temp = PDM(P = p_ep_zwalm['total_precipitation_sum'].values, \n",
    "            EP = p_ep_zwalm['potential_evaporation_sum'].values, t = p_ep_zwalm['Timestamp'].values,\n",
    "            area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,parameters = param_set_temp\n",
    "    )\n",
    "    flow_dict_test[index_temp] = pd_zwalm_out_temp['qmodm3s'][pd_zwalm_out.index >= start_p2]\n",
    "    Cstar_nm_dict[index_temp] = pd_zwalm_out_temp['Cstar'][pd_zwalm_out.index >= start_p2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_dict = flow_dict_test\n",
    "print(flow_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_bool = nan_bool[nan_bool.index >= start_p2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow_dict[49].values[~nan_bool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_quan = np.sort(Q_day['streamflow'][Q_day.index >= start_p2].dropna())\n",
    "print(len(obs_quan))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sort has the same effect as quantile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')  # Set plot style\n",
    "\n",
    "# Create figure with specified size\n",
    "fig, ax = plt.subplots(figsize=(6.3, 3.5))\n",
    "\n",
    "# Plot the ideal line\n",
    "ax.plot(obs_quan, obs_quan, label='Ideal Prediction')\n",
    "temp_quantile = np.sort(flow_dict[29].values[~nan_bool])\n",
    "ax.plot(obs_quan, temp_quantile, linewidth=1, marker='o', markersize=2, label=29)\n",
    "# Grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Rotate x-axis ticks if needed (can be skipped for QQ plots, but included per your request)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')  # Set plot style\n",
    "\n",
    "# Create figure with specified size\n",
    "fig, ax = plt.subplots(figsize=(6.3, 3.5))\n",
    "\n",
    "\n",
    "\n",
    "# Get the first key for the prediction with the highest NSE\n",
    "highest_nse_key = list(flow_dict.keys())[0]  # Assuming the first key corresponds to highest NSE\n",
    "\n",
    "# Plot each parameter set\n",
    "for key in flow_dict.keys():\n",
    "    temp_quantile = np.sort(flow_dict[key].values[~nan_bool])\n",
    "    \n",
    "    # Apply a different style for the first key (highest NSE)\n",
    "    if key == highest_nse_key:\n",
    "        highest_nse_line, = ax.plot(obs_quan, temp_quantile, linewidth=3, color='red', marker='d', markersize=5, label='Prediction with Highest NSE in Validation Period', zorder=2)\n",
    "    else:\n",
    "        ax.plot(obs_quan, temp_quantile, linewidth=1, marker='o', markersize=2, label=key, zorder=1)\n",
    "\n",
    "# Plot the ideal line\n",
    "ideal_line, = ax.plot(obs_quan, obs_quan, label='Ideal Prediction',linewidth=3, color='black', zorder=3)\n",
    "# Grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Rotate x-axis ticks if needed (can be skipped for QQ plots, but included per your request)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add legend with the correct handles\n",
    "ax.legend(handles=[ideal_line, highest_nse_line], \n",
    "          labels=['Ideal Prediction', 'Highest NSE'], \n",
    "          frameon=True, edgecolor='black')\n",
    "\n",
    "# Add axis labels and styling\n",
    "plt.xlabel('Discharge (m³/s)', fontsize=12)\n",
    "plt.ylabel('Discharge (m³/s)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.savefig(\"50_plots_PDM.png\", dpi=1000, bbox_inches='tight') \n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,5))\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "Q_day['streamflow'].plot(label = 'Geobserveerd', ax = ax) \n",
    "pd_zwalm_out_opt['qmodm3s'].plot(label = 'Gekalibreerd PDM', ax =ax)\n",
    "ax.set_ylabel('$Q$ [m$^3$/s]')\n",
    "ax.set_xlabel('Tijd')\n",
    "ax.legend()\n",
    "pad = Path('Figures/presentation_12_04')\n",
    "if not os.path.exists(pad):\n",
    "    os.makedirs(pad)\n",
    "plt.savefig(pad/'hydrogram.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "\n",
    "file_path = parent / 'data' /'Zwalm_PDM_parameters' / 'NM_NSE_performances_50.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "x = data['NSE_val']\n",
    "y = data['FHV_val']\n",
    "# Identify the point with the highest NSE_val\n",
    "highest_nse_index = data['NSE_val'].idxmax()\n",
    "highest_nse_point = data.loc[highest_nse_index]\n",
    "\n",
    "print(highest_nse_index)\n",
    "print(highest_nse_point)\n",
    "\n",
    "# Separate points into green and red based on FHV proximity to 0\n",
    "data['Color'] = np.where(np.abs(data['FHV_val']) < np.abs(highest_nse_point['FHV_val']), 'green', 'red')\n",
    "\n",
    "# Count green and red points\n",
    "green_count = (data['Color'] == 'green').sum()\n",
    "red_count = (data['Color'] == 'red').sum() - 1  # Exclude the highest NSE point\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(6.3, 3.5))\n",
    "for color, group in data.groupby('Color'):\n",
    "    label = 'Better FHV' if color == 'green' else 'Worse FHV'\n",
    "    plt.scatter(group['NSE_val'], group['FHV_val'], label=f\"{label}\", \n",
    "                color=color, alpha=0.7, edgecolor='k', s=50)\n",
    "\n",
    "# Highlight the point with the highest NSE_val\n",
    "plt.scatter(highest_nse_point['NSE_val'], highest_nse_point['FHV_val'], \n",
    "            color='blue', edgecolor='black', s=50, label='FHV of Highest NSE')\n",
    "\n",
    "plt.xlabel('NSE in Validation Period', fontsize=12)\n",
    "plt.ylabel('FHV in Validation Period', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(frameon=True, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.axhline(y=0, color='black', linewidth=3)\n",
    "plt.savefig(\"FHV_PDM_plot.png\", dpi=1000, bbox_inches='tight') \n",
    "plt.show()\n",
    "\n",
    "# Display the counts\n",
    "green_count, red_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_dict_test = {}\n",
    "Cstar_nm_dict = {}\n",
    "top_nr = 50\n",
    "for i in range(top_nr):\n",
    "    param_set_temp = pd.DataFrame(pd_opt_params.iloc[i,:].to_dict(), index = [0])\n",
    "    pd_zwalm_out_temp = PDM(P = p_ep_zwalm['total_precipitation_sum'].values, \n",
    "            EP = p_ep_zwalm['potential_evaporation_sum'].values, t = p_ep_zwalm['Timestamp'].values,\n",
    "            area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,parameters = param_set_temp\n",
    "    )\n",
    "    flow_dict_test[i] = pd_zwalm_out_temp['qmodm3s'][pd_zwalm_out.index >= start_p2]\n",
    "    Cstar_nm_dict[i] = pd_zwalm_out_temp['Cstar'][pd_zwalm_out.index >= start_p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow_dict_test[0].values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_pred_avg = {key: flow_dict_test[key].values[~nan_bool].mean() for key in flow_dict_test}\n",
    "print(Q_pred_avg)\n",
    "Q_pred_avg_df = pd.DataFrame.from_dict(Q_pred_avg, orient='index', columns=['Q_pred_avg'])\n",
    "Q_pred_avg_df.reset_index(inplace=True)\n",
    "Q_pred_avg_df.rename(columns={'index': 'key'}, inplace=True)\n",
    "\n",
    "obs_quan = Q_day['streamflow'][Q_day.index >= start_p2].dropna()\n",
    "# Normalize by observed mean\n",
    "obs_quan_avg = obs_quan.mean()\n",
    "print(obs_quan)\n",
    "print(obs_quan_avg)\n",
    "Q_pred_avg_df['Q_pred_avg_2'] = Q_pred_avg_df['Q_pred_avg'] / obs_quan_avg\n",
    "print(Q_pred_avg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = parent / 'data' /'Zwalm_PDM_parameters' / 'NM_NSE_performances_50.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Merge the Q_pred_avg_df with data based on the shared key\n",
    "merged_df = pd.concat([data.reset_index(drop=True), Q_pred_avg_df['Q_pred_avg_2'].reset_index(drop=True)], axis=1)\n",
    "print(merged_df)\n",
    "# Identify the point with the highest NSE_val\n",
    "highest_nse_index = merged_df['NSE_val'].idxmax()\n",
    "highest_nse_point = merged_df.loc[highest_nse_index]\n",
    "print(highest_nse_index)\n",
    "print(highest_nse_point)\n",
    "# Define color condition: closer to 1 = better beta\n",
    "merged_df['Color'] = np.where(np.abs(merged_df['Q_pred_avg_2'] - 1) < np.abs(highest_nse_point['Q_pred_avg_2'])-1, 'green', 'red')\n",
    "print(np.abs(highest_nse_point['Q_pred_avg_2']))\n",
    "# Count green and red points\n",
    "green_count = (merged_df['Color'] == 'green').sum()\n",
    "red_count = (merged_df['Color'] == 'red').sum()-1\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6.3, 3.5))\n",
    "for color, group in merged_df.groupby('Color'):\n",
    "    label = r'Better $\\beta_{\\mathrm{KGE}}$' if color == 'green' else r'Worse $\\beta_{\\mathrm{KGE}}$'\n",
    "    plt.scatter(group['NSE_val'], group['Q_pred_avg_2'], label=label,\n",
    "                color=color, alpha=0.7, edgecolor='k', s=50)\n",
    "\n",
    "# Highlight best NSE point\n",
    "plt.scatter(highest_nse_point['NSE_val'], highest_nse_point['Q_pred_avg_2'],\n",
    "            color='blue', edgecolor='black', s=50, label='Best NSE')\n",
    "\n",
    "plt.xlabel('NSE in Validation Period', fontsize=12)\n",
    "plt.ylabel(r'$\\beta_{\\mathrm{KGE}}$ in Validation Period', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(frameon=True, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.axhline(y=1, color='black', linewidth=3) # target beta\n",
    "plt.savefig(\"beta-KGE_PDM.png\", dpi=1000, bbox_inches='tight') \n",
    "plt.show()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Green points (better beta):\", green_count)\n",
    "print(\"Red points (worse beta):\", red_count)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final parameter set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set with the best performance (based on NSE and mNSE of the validation set) is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_NM = pd.DataFrame(best_param_set.values.reshape(1,-1), columns = pd_init_params.columns)\n",
    "best_param_NM.to_csv(\"data/Zwalm_PDM_parameters/NM_opt_param.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_dict_test = {}\n",
    "Cstar_nm_dict = {}\n",
    "top_nr = 3\n",
    "for i in range(top_nr):\n",
    "    index_temp = sorted_score.iloc[i,:].name\n",
    "    param_set_temp = pd.DataFrame(pd_opt_params.iloc[index_temp,:].to_dict(), index = [0])\n",
    "    pd_zwalm_out_temp = PDM(P = p_ep_zwalm['total_precipitation_sum'].values, \n",
    "            EP = p_ep_zwalm['potential_evaporation_sum'].values, t = p_ep_zwalm['Timestamp'].values,\n",
    "            area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,parameters = param_set_temp\n",
    "    )\n",
    "    flow_dict_test[index_temp] = pd_zwalm_out_temp['qmodm3s'][pd_zwalm_out.index >= start_p2]\n",
    "    Cstar_nm_dict[index_temp] = pd_zwalm_out_temp['Cstar'][pd_zwalm_out.index >= start_p2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flow_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Concatenate all series into a DataFrame\n",
    "df_ensemble = pd.concat(flow_dict_test.values(), axis=1)\n",
    "\n",
    "\n",
    "# Step 3: Compute the row-wise mean (ensemble average)\n",
    "ensemble_mean = df_ensemble.mean(axis=1)\n",
    "\n",
    "# Step 4: Save to a new DataFrame\n",
    "df_ensemble_avg = pd.DataFrame({'ensemble_avg_qmodm3s': ensemble_mean})\n",
    "\n",
    "# Optional: Inspect the result\n",
    "print(df_ensemble_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_quan = Q_day['streamflow'][Q_day.index >= start_p2]\n",
    "print(obs_quan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_quan = obs_quan.to_frame(name='observed')\n",
    "obs_quan['ensemble_avg_qmodm3s'] = df_ensemble_avg['ensemble_avg_qmodm3s'].values\n",
    "\n",
    "print(obs_quan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSE(obs_quan['ensemble_avg_qmodm3s'], obs_quan['observed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV(obs_quan['ensemble_avg_qmodm3s'], obs_quan['observed'], exceedance_prob=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgobs = obs_quan['observed'].mean(skipna=True)\n",
    "print(avgobs)\n",
    "avgsim = obs_quan['ensemble_avg_qmodm3s'].mean()\n",
    "print(avgsim)\n",
    "avgsim/avgobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSE_LF(obs_quan['ensemble_avg_qmodm3s'], obs_quan['observed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.3, 3.5))\n",
    "\n",
    "# Plot observed streamflow\n",
    "plt.plot(obs_quan.index, obs_quan['observed'], label='Observed Discharge', color='blue', linewidth=1)\n",
    "\n",
    "# Plot simulated streamflow\n",
    "plt.plot(obs_quan.index, obs_quan['ensemble_avg_qmodm3s'], label='Simulated Discharge', color='red', linewidth = 1)\n",
    "\n",
    "# Add axis labels and styling\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Discharge (m³/s)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(frameon=True, edgecolor='black',fontsize = 10)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.savefig(\"Final_output_PDM.png\", dpi=1000, bbox_inches='tight') \n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

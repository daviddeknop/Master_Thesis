{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import warnings\n",
    "import pyswarms as ps\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the function to convert datetime to Julian day number\n",
    "def to_julian_day(timestamp):\n",
    "    return timestamp.to_pydatetime().toordinal() + 1721424.5 + (\n",
    "        timestamp.hour / 24.0\n",
    "    ) + (timestamp.minute / 1440.0) + (timestamp.second / 86400.0)\n",
    "\n",
    "# Path to the preprocess output folder\n",
    "current_dir = Path(os.getcwd())  # Use Path to enable .parent\n",
    "current_dir = current_dir.parent\n",
    "preprocess_output_folder = current_dir / 'data' / 'Zwalm_data' / 'preprocess_output'\n",
    "\n",
    "\n",
    "\n",
    "# Read the pickle file\n",
    "p_ep_zwalm = pd.read_pickle(preprocess_output_folder / 'forcings_ERA5_david_E_EP.pkl')\n",
    "\n",
    "# Check the data type of the 'Timestamp' column\n",
    "print(p_ep_zwalm['Timestamp'].dtype)\n",
    "print(p_ep_zwalm.head())\n",
    "\n",
    "# Apply the to_julian_day function to calculate Julian numbers\n",
    "p_ep_zwalm['Julian_Number'] = p_ep_zwalm['Timestamp'].apply(to_julian_day)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(p_ep_zwalm)\n",
    "print(p_ep_zwalm['Julian_Number'][1])\n",
    "\n",
    "def calculate_solar_declination(julian_number):\n",
    "    return 0.4093 * np.sin((2 * np.pi * julian_number / 365) - 1.405)\n",
    "\n",
    "p_ep_zwalm['solar_declination'] = p_ep_zwalm['Julian_Number'].apply(calculate_solar_declination)\n",
    "print(p_ep_zwalm[['Julian_Number', 'solar_declination']][20:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "path = current_dir / 'output_caravan' / 'timeseries' / 'netcdf' / 'vlaamsebekken' /'6.nc'\n",
    "\n",
    "#path = Path('output_caravan/timeseries/netcdf/vlaamsebekken/6.nc')\n",
    "\n",
    "ds = xr.open_dataset(path)\n",
    "\n",
    "# Convert to pandas DataFrame if needed\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "# Step 1: Convert the index to datetime if it's not already in datetime format\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Step 2: Define the desired date range for the final DataFrame\n",
    "start_date = pd.to_datetime('1972-07-01')\n",
    "end_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "# Step 3: Filter the DataFrame to include only rows within the date range\n",
    "df_filtered = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "\n",
    "# Step 4: Create a new index with hourly frequency for each day in the range\n",
    "new_index = pd.date_range(start=start_date, end=end_date + pd.Timedelta(days=1) - pd.Timedelta(hours=1), freq='H')\n",
    "\n",
    "# Step 5: Repeat each row 24 times for each day to create a new row for every hour\n",
    "df_expanded = df_filtered.loc[df_filtered.index.repeat(24)].reset_index(drop=True)\n",
    "\n",
    "# Step 6: Assign the new hourly index to the expanded DataFrame\n",
    "df_expanded.index = new_index\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "\n",
    "p_ep_zwalm['T_avg'] = df_expanded['temperature_2m_mean'].values\n",
    "print(df_expanded.shape[0])\n",
    "print(p_ep_zwalm.shape[0])\n",
    "print(p_ep_zwalm['T_avg'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(path)\n",
    "\n",
    "# Convert to pandas DataFrame if needed\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "# Step 1: Convert the index to datetime if it's not already in datetime format\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Step 2: Define the desired date range for the final DataFrame\n",
    "start_date = pd.to_datetime('1972-07-01')\n",
    "end_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "# Step 3: Filter the DataFrame to include only rows within the date range\n",
    "df_filtered = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "df_filtered = df_expanded[['temperature_2m_min', 'temperature_2m_max',]]\n",
    "df_filtered['T_min'] = df_filtered.groupby(df_filtered.index.to_period('M'))['temperature_2m_min'].transform('min')\n",
    "df_filtered['T_max'] = df_filtered.groupby(df_filtered.index.to_period('M'))['temperature_2m_max'].transform('max')\n",
    "df_filtered['T_diff'] = df_filtered['T_max']-df_filtered['T_min']\n",
    "\n",
    "print(df_filtered)\n",
    "p_ep_zwalm['T_diff'] = df_filtered['T_diff'].values\n",
    "print(df_filtered.shape[0])\n",
    "print(p_ep_zwalm.shape[0])\n",
    "print(p_ep_zwalm['T_diff'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(path)\n",
    "\n",
    "# Convert to pandas DataFrame if needed\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "\n",
    "#  Step 1: Convert the index to datetime if it's not already in datetime format\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Step 2: Define the desired date range for the final DataFrame\n",
    "start_date = pd.to_datetime('1972-07-01')\n",
    "end_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "# Step 3: Filter the DataFrame to include only rows within the date range\n",
    "df_filtered = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "df_filtered = df_filtered[['total_precipitation_sum']]\n",
    "print(df_filtered)\n",
    "df_filtered['P_tot'] = df_filtered.groupby(df_filtered.index.to_period('M'))['total_precipitation_sum'].transform('sum')\n",
    "print(df_filtered)\n",
    "# Step 4: Create a new index with hourly frequency for each day in the range\n",
    "new_index = pd.date_range(start=start_date, end=end_date + pd.Timedelta(days=1) - pd.Timedelta(hours=1), freq='H')\n",
    "\n",
    "# Step 5: Repeat each row 24 times for each day to create a new row for every hour\n",
    "df_expanded = df_filtered.loc[df_filtered.index.repeat(24)].reset_index(drop=True)\n",
    "\n",
    "# Step 6: Assign the new hourly index to the expanded DataFrame\n",
    "df_expanded.index = new_index\n",
    "print(df_expanded)\n",
    "p_ep_zwalm['P_tot'] = df_expanded['P_tot'].values\n",
    "print(p_ep_zwalm['P_tot'])\n",
    "print(df_filtered['P_tot'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = Path('output_caravan/attributes/vlaamsebekken/attributes_other_vlaamsebekken.csv')\n",
    "path = current_dir / 'output_caravan' / 'attributes' / 'vlaamsebekken' / 'attributes_other_vlaamsebekken.csv'\n",
    "lat = pd.read_csv(path)\n",
    "latitude= lat['gauge_lat']\n",
    "\n",
    "p_ep_zwalm = p_ep_zwalm.assign(latitude=latitude)\n",
    "p_ep_zwalm['latitude'] = p_ep_zwalm.iloc[0]['latitude']\n",
    "# Calculate latitude in radians\n",
    "p_ep_zwalm['latitude'] = np.radians(p_ep_zwalm['latitude'])\n",
    "print(p_ep_zwalm['latitude'])\n",
    "p_ep_zwalm['omega_s'] = np.arccos(-np.tan(p_ep_zwalm['latitude']) * np.tan(p_ep_zwalm['solar_declination']))\n",
    "\n",
    "\n",
    "\n",
    "def calculate_dr(J):\n",
    "    d_r = 1 + 0.033 * np.cos(2 * np.pi * J / 365)\n",
    "    return d_r\n",
    "\n",
    "p_ep_zwalm['dr'] = p_ep_zwalm['Julian_Number'].apply(calculate_dr)\n",
    "\n",
    "\n",
    "def calculate_S0(d_r, omega_s, phi, delta):\n",
    "    S_0 = 15.392 * d_r * (omega_s * np.sin(phi) * np.sin(delta) + np.cos(phi) * np.cos(delta) * np.sin(omega_s))\n",
    "    return S_0\n",
    "\n",
    "p_ep_zwalm['S0'] = calculate_S0(p_ep_zwalm['dr'],p_ep_zwalm['omega_s'],p_ep_zwalm['latitude'],p_ep_zwalm['solar_declination'])\n",
    "\n",
    "\n",
    "def calculate_E(S_0, T_avg_t, T_diff_t_prime, P_t_prime):\n",
    "    E_t = 0.0013 * S_0 * (T_avg_t + 17.0) * (T_diff_t_prime - 0.0123 * P_t_prime)**0.76\n",
    "    return E_t\n",
    "p_ep_zwalm['potential_evaporation_sum'] = (calculate_E(p_ep_zwalm['S0'].values,p_ep_zwalm['T_avg'].values,p_ep_zwalm['T_diff'].values,p_ep_zwalm['P_tot'].values))/24\n",
    "\n",
    "\n",
    "print(p_ep_zwalm['P_tot'])\n",
    "print(p_ep_zwalm['potential_evaporation_sum'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_ep_zwalm['omega_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where you want to save the pickle file\n",
    "file_path = current_dir / \"data\" / \"Zwalm_data\" / \"preprocess_output\" / \"p_ep_with_adaptions_ep.pkl'\n",
    "\n",
    "# Save the DataFrame as a pickle file\n",
    "p_ep_zwalm.to_pickle(file_path)\n",
    "\n",
    "print(f\"DataFrame saved to {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

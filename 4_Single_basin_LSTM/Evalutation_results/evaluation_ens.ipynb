{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from neuralhydrology.evaluation import metrics\n",
    "from neuralhydrology.nh_run import start_run, eval_run\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "import numpy as np\n",
    "area = 100588192.142945\n",
    "\n",
    "# Base directory containing the test results\n",
    "cwd = Path(os.getcwd())\n",
    "parent_wd = cwd.parent\n",
    "run_dir1 = Path(parent_wd / 'runs/...') # fill in with your created output file\n",
    "base_dir1 = Path(parent_wd / 'runs/...') # fill in with your created output file\n",
    "\n",
    "run_dir2 = Path(parent_wd / 'runs/...') # fill in with your created output file\n",
    "base_dir2 = Path(parent_wd / 'runs/...') # fill in with your created output file\n",
    "\n",
    "run_dir3 = Path(parent_wd / 'runs/...') # fill in with your created output file\n",
    "base_dir3 = Path(parent_wd / 'runs/...') # fill in with your created output file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables to track the best NSE and the corresponding epoch\n",
    "max_nse = -float('inf')  # Set to negative infinity initially\n",
    "best_epoch = None\n",
    "\n",
    "# Loop through epochs 1 to 50\n",
    "for i in range(1, 51):  # Epochs 1 to 50\n",
    "    # Format the folder name for the current epoch\n",
    "    epoch_folder = base_dir1 / f\"model_epoch{i:03d}\"\n",
    "    metrics_file = epoch_folder / \"test_metrics.csv\"\n",
    "\n",
    "    # Check if the test_metrics.csv file exists\n",
    "    if not metrics_file.exists():\n",
    "        print(f\"test_metrics.csv file not found for epoch {i}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(metrics_file)\n",
    "\n",
    "    # Extract the NSE value from the dataframe (assuming NSE is in a column named 'NSE')\n",
    "    if 'NSE' in df.columns:\n",
    "        nse_value = df['NSE'].iloc[0]  \n",
    "        print(f\"Epoch {i}: NSE = {nse_value:.4f}\")\n",
    "\n",
    "        # Check if this is the highest NSE found so far\n",
    "        if nse_value > max_nse:\n",
    "            max_nse = nse_value\n",
    "            best_epoch = i\n",
    "\n",
    "# Output the best epoch and its NSE value\n",
    "if best_epoch is not None:\n",
    "    print(f\"\\nThe epoch with the highest NSE is Epoch {best_epoch} with an NSE value of {max_nse:.4f}\")\n",
    "else:\n",
    "    print(\"No NSE values found.\")\n",
    "\n",
    "\n",
    "with open(run_dir1 / \"test\" / \"model_epoch...\" / \"test_results.p\", \"rb\") as fp: # fill in with your best epoch\n",
    "    results = pickle.load(fp)\n",
    "qobs = results['7']['1D']['xr']['streamflow_obs']*area/(1000*3600*24)\n",
    "qsim = results['7']['1D']['xr']['streamflow_sim']*area/(1000*3600*24)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "ax.plot(qobs['date'], qobs)\n",
    "ax.plot(qsim['date'], qsim)\n",
    "ax.set_ylabel(\"Discharge (m³/s)\")\n",
    "\n",
    "    #data properties\n",
    "\n",
    "values = metrics.calculate_all_metrics(qobs.isel(time_step=-1), qsim.isel(time_step=-1))\n",
    "for key, val in values.items():\n",
    "    print(f\"{key}: {val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a874173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables to track the best NSE and the corresponding epoch\n",
    "max_nse = -float('inf')  # Set to negative infinity initially\n",
    "best_epoch = None\n",
    "\n",
    "# Loop through epochs 1 to 50\n",
    "for i in range(1, 51):  # Epochs 1 to 50\n",
    "    # Format the folder name for the current epoch\n",
    "    epoch_folder = base_dir2 / f\"model_epoch{i:03d}\"\n",
    "    metrics_file = epoch_folder / \"test_metrics.csv\"\n",
    "\n",
    "    # Check if the test_metrics.csv file exists\n",
    "    if not metrics_file.exists():\n",
    "        print(f\"test_metrics.csv file not found for epoch {i}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(metrics_file)\n",
    "\n",
    "    # Extract the NSE value from the dataframe (assuming NSE is in a column named 'NSE')\n",
    "    if 'NSE' in df.columns:\n",
    "        nse_value = df['NSE'].iloc[0]  \n",
    "        print(f\"Epoch {i}: NSE = {nse_value:.4f}\")\n",
    "\n",
    "        # Check if this is the highest NSE found so far\n",
    "        if nse_value > max_nse:\n",
    "            max_nse = nse_value\n",
    "            best_epoch = i\n",
    "\n",
    "# Output the best epoch and its NSE value\n",
    "if best_epoch is not None:\n",
    "    print(f\"\\nThe epoch with the highest NSE is Epoch {best_epoch} with an NSE value of {max_nse:.4f}\")\n",
    "else:\n",
    "    print(\"No NSE values found.\")\n",
    "\n",
    "\n",
    "with open(run_dir2 / \"test\" / \"model_epoch...\" / \"test_results.p\", \"rb\") as fp: # fill in with your best epoch\n",
    "    results = pickle.load(fp)\n",
    "qobs = results['7']['1D']['xr']['streamflow_obs']*area/(1000*3600*24)\n",
    "qsim = results['7']['1D']['xr']['streamflow_sim']*area/(1000*3600*24)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "ax.plot(qobs['date'], qobs)\n",
    "ax.plot(qsim['date'], qsim)\n",
    "ax.set_ylabel(\"Discharge (m³/s)\")\n",
    "\n",
    "    #data properties\n",
    "\n",
    "values = metrics.calculate_all_metrics(qobs.isel(time_step=-1), qsim.isel(time_step=-1))\n",
    "for key, val in values.items():\n",
    "    print(f\"{key}: {val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables to track the best NSE and the corresponding epoch\n",
    "max_nse = -float('inf')  # Set to negative infinity initially\n",
    "best_epoch = None\n",
    "\n",
    "# Loop through epochs 1 to 50\n",
    "for i in range(1, 51):  # Epochs 1 to 50\n",
    "    # Format the folder name for the current epoch\n",
    "    epoch_folder = base_dir3 / f\"model_epoch{i:03d}\"\n",
    "    metrics_file = epoch_folder / \"test_metrics.csv\"\n",
    "\n",
    "    # Check if the test_metrics.csv file exists\n",
    "    if not metrics_file.exists():\n",
    "        print(f\"test_metrics.csv file not found for epoch {i}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(metrics_file)\n",
    "\n",
    "    # Extract the NSE value from the dataframe (assuming NSE is in a column named 'NSE')\n",
    "    if 'NSE' in df.columns:\n",
    "        nse_value = df['NSE'].iloc[0]  \n",
    "        print(f\"Epoch {i}: NSE = {nse_value:.4f}\")\n",
    "\n",
    "        # Check if this is the highest NSE found so far\n",
    "        if nse_value > max_nse:\n",
    "            max_nse = nse_value\n",
    "            best_epoch = i\n",
    "\n",
    "# Output the best epoch and its NSE value\n",
    "if best_epoch is not None:\n",
    "    print(f\"\\nThe epoch with the highest NSE is Epoch {best_epoch} with an NSE value of {max_nse:.4f}\")\n",
    "else:\n",
    "    print(\"No NSE values found.\")\n",
    "\n",
    "\n",
    "with open(run_dir3 / \"test\" / \"model_epoch...\" / \"test_results.p\", \"rb\") as fp: # fill in with your best epoch\n",
    "    results = pickle.load(fp)\n",
    "qobs = results['7']['1D']['xr']['streamflow_obs']*area/(1000*3600*24)\n",
    "qsim = results['7']['1D']['xr']['streamflow_sim']*area/(1000*3600*24)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "ax.plot(qobs['date'], qobs)\n",
    "ax.plot(qsim['date'], qsim)\n",
    "ax.set_ylabel(\"Discharge (m³/s)\")\n",
    "\n",
    "    #data properties\n",
    "\n",
    "values = metrics.calculate_all_metrics(qobs.isel(time_step=-1), qsim.isel(time_step=-1))\n",
    "for key, val in values.items():\n",
    "    print(f\"{key}: {val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a9e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FHV(Qmod, Qobs, exceedance_prob=0.02):\n",
    "    \"\"\"\n",
    "    Calculate the percentage bias in percent bias in flow duration curve high-segment volume (FHV) as defined in Yilmaz et al. (2008)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Qmod: numpy.array\n",
    "        modelled flows\n",
    "    Qobs: numpy.array\n",
    "        observed flows\n",
    "    exceedance_prob: float, default = 0.02\n",
    "        highest fraction of flows to take into account for calculation of the bias\n",
    "    Returns\n",
    "    --------\n",
    "    fhv: float\n",
    "        percentage bias in percent bias in flow duration curve high-segment volume\n",
    "\n",
    "    \"\"\"\n",
    "    nan_bool = np.isnan(Qobs)\n",
    "    Qmod_nonan = Qmod[~nan_bool]\n",
    "    Qobs_nonan = Qobs[~nan_bool]\n",
    "    Q_mod_sorted = np.sort(Qmod_nonan)\n",
    "    Q_obs_sorted = np.sort(Qobs_nonan)\n",
    "\n",
    "    CDF_obs_distribution = ECDF(Q_obs_sorted)\n",
    "    CDF_obs = CDF_obs_distribution(Q_obs_sorted)\n",
    "    CDF_mod_distribution = ECDF(Q_mod_sorted)\n",
    "    CDF_mod = CDF_mod_distribution(Q_mod_sorted)\n",
    "\n",
    "    Q_obs_H = Q_obs_sorted[CDF_obs > 1 - exceedance_prob]\n",
    "    Q_mod_H = Q_mod_sorted[CDF_mod > 1 - exceedance_prob]\n",
    "    if len(Q_obs_H) != len(Q_mod_H):\n",
    "        # occurs when e.g. modesl produces a constant input\n",
    "        if len(Q_obs_H) < len(Q_mod_H):\n",
    "            len_obs = len(Q_obs_H)\n",
    "            Q_mod_H = Q_mod_H[0:len_obs]\n",
    "        else: \n",
    "            len_mod = len(Q_mod_H)\n",
    "            Q_obs_H = Q_obs_H[0:len_mod]\n",
    "    fhv = 100 * np.nansum(Q_mod_H - Q_obs_H) / np.nansum(Q_obs_H)\n",
    "    return fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab499063",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qobs)\n",
    "print(qsim)\n",
    "qsim_avg = qsim.mean(skipna = True)\n",
    "qobs_avg = qobs.mean(skipna=True)\n",
    "print(qsim_avg)\n",
    "print(qobs_avg)\n",
    "qsim_avg.values/qobs_avg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b38cb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NSE_LF(Qmod, Qobs):\n",
    "    \"\"\"\n",
    "    Calculate the low-flow Nash-Sutcliffe Efficiency (NSE_LF) using inverse flows.\n",
    "    This variant of NSE emphasizes performance during low-flow periods.\n",
    "\n",
    "    Only calculates for timestamps where no NaN values are present in the observed flows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Qmod: numpy.array\n",
    "        Modelled flows\n",
    "    Qobs: numpy.array\n",
    "        Observed flows\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nse_lf: float\n",
    "        Low-flow Nash-Sutcliffe Efficiency\n",
    "\n",
    "    \"\"\"\n",
    "    nan_bool = np.isnan(Qobs)\n",
    "    Qmod_nonan = Qmod[~nan_bool]\n",
    "    Qobs_nonan = Qobs[~nan_bool]\n",
    "\n",
    "    # Avoid division by zero using epsilon (1/100th of mean observed flow)\n",
    "    epsilon = np.mean(Qobs_nonan) / 100\n",
    "\n",
    "    Qmod_inv = 1 / (Qmod_nonan + epsilon)\n",
    "    Qobs_inv = 1 / (Qobs_nonan + epsilon)\n",
    "\n",
    "    T = (Qobs_inv - Qmod_inv) ** 2\n",
    "    N = (Qobs_inv - np.mean(Qobs_inv)) ** 2\n",
    "\n",
    "    nse_lf = 1 - np.sum(T) / np.sum(N)\n",
    "    return nse_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ad77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSE_LF(qsim.values, qobs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "fhv = FHV(qsim.values, qobs.values, exceedance_prob=0.02)\n",
    "print(fhv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d970c",
   "metadata": {},
   "source": [
    "Vanaf hier ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Best epochs for each run directory\n",
    "epochs = [...,...,...] # fill in with your best epoch per model\n",
    "\n",
    "# Initialize an empty dictionary to hold the ensemble mean results\n",
    "ensemble_mean = {}\n",
    "\n",
    "# Loop through each run directory and corresponding epoch\n",
    "for run_dir, epoch in zip([run_dir1, run_dir2, run_dir3], epochs):\n",
    "    # Define the path to the results file for the specified epoch\n",
    "    test_results_path = run_dir / \"test\" / f\"model_epoch{epoch:03}\" / \"test_results.p\"\n",
    "\n",
    "    # Load the results from the pickle file\n",
    "    with open(test_results_path, \"rb\") as fp:\n",
    "        results = pickle.load(fp)\n",
    "\n",
    "    # Extract observed and simulated streamflow data\n",
    "    # Note: Adjust the basin id (here '6') and timestep ('1D') as needed\n",
    "    qobs = results['7']['1D']['xr']['streamflow_obs'] * area / (1000 * 3600 * 24)\n",
    "    qsim = results['7']['1D']['xr']['streamflow_sim'] * area / (1000 * 3600 * 24)\n",
    "\n",
    "    # Store the simulations (this will be used to calculate the ensemble mean later)\n",
    "    ensemble_mean[run_dir] = qsim\n",
    "\n",
    "# Now calculate the ensemble mean across the different runs\n",
    "# Assuming all simulations are aligned by basin and timestep\n",
    "qsim_ensemble = np.mean(np.stack(list(ensemble_mean.values())), axis=0)\n",
    "\n",
    "# To calculate NSE for the ensemble mean, first load the observed data (qobs)\n",
    "# Assuming observed data is same for all runs, so you can just load it once from any of the runs\n",
    "qobs = results['7']['1D']['xr']['streamflow_obs'] * area / (1000 * 3600 * 24)\n",
    "\n",
    "# Define the NSE calculation function\n",
    "def nse(simulated, observed):\n",
    "    return 1 - np.sum((simulated - observed) ** 2) / np.sum((observed - np.mean(observed)) ** 2)\n",
    "\n",
    "print(qsim_ensemble)\n",
    "print(qobs)\n",
    "# Calculate NSE for the ensemble mean\n",
    "nse_ensemble = nse(qsim_ensemble, qobs)\n",
    "\n",
    "print(f'Ensemble mean NSE: {nse_ensemble}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(qsim))\n",
    "print(len(qobs))\n",
    "print(qobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b80f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.3, 3.5))\n",
    "\n",
    "# Plot observed streamflow\n",
    "plt.plot(qobs['date'], qobs, label='Observed Discharge', color='blue', linewidth=1)\n",
    "\n",
    "# Plot simulated streamflow\n",
    "plt.plot(qobs['date'], qsim_ensemble, label='Simulated Discharge', color='red', linewidth = 1)\n",
    "\n",
    "# Add axis labels and styling\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Discharge (m³/s)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(frameon=True, edgecolor='black')\n",
    "plt.savefig(\"Bellebeek_plot_single_basin.png\", dpi=1000, bbox_inches='tight') \n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d628ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qobs_isna = np.isnan(qobs.values)\n",
    "qobs_isna_def = qobs.values[~qobs_isna]\n",
    "qobs_mean =qobs_isna_def.mean()\n",
    "print(qobs_mean)\n",
    "\n",
    "\n",
    "qsim_ensemble_mean =qsim_ensemble.mean()\n",
    "print(qsim_ensemble_mean)\n",
    "\n",
    "qsim_ensemble_mean/qobs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8d6599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FHV(Qmod, Qobs, exceedance_prob=0.02):\n",
    "    \"\"\"\n",
    "    Calculate the percentage bias in percent bias in flow duration curve high-segment volume (FHV) as defined in Yilmaz et al. (2008)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Qmod: numpy.array\n",
    "        modelled flows\n",
    "    Qobs: numpy.array\n",
    "        observed flows\n",
    "    exceedance_prob: float, default = 0.02\n",
    "        highest fraction of flows to take into account for calculation of the bias\n",
    "    Returns\n",
    "    --------\n",
    "    fhv: float\n",
    "        percentage bias in percent bias in flow duration curve high-segment volume\n",
    "\n",
    "    \"\"\"\n",
    "    nan_bool = np.isnan(Qobs)\n",
    "    Qmod_nonan = Qmod[~nan_bool]\n",
    "    Qobs_nonan = Qobs[~nan_bool]\n",
    "    Q_mod_sorted = np.sort(Qmod_nonan)\n",
    "    Q_obs_sorted = np.sort(Qobs_nonan)\n",
    "\n",
    "    CDF_obs_distribution = ECDF(Q_obs_sorted)\n",
    "    CDF_obs = CDF_obs_distribution(Q_obs_sorted)\n",
    "    CDF_mod_distribution = ECDF(Q_mod_sorted)\n",
    "    CDF_mod = CDF_mod_distribution(Q_mod_sorted)\n",
    "\n",
    "    Q_obs_H = Q_obs_sorted[CDF_obs > 1 - exceedance_prob]\n",
    "    Q_mod_H = Q_mod_sorted[CDF_mod > 1 - exceedance_prob]\n",
    "    if len(Q_obs_H) != len(Q_mod_H):\n",
    "        # occurs when e.g. modesl produces a constant input\n",
    "        if len(Q_obs_H) < len(Q_mod_H):\n",
    "            len_obs = len(Q_obs_H)\n",
    "            Q_mod_H = Q_mod_H[0:len_obs]\n",
    "        else: \n",
    "            len_mod = len(Q_mod_H)\n",
    "            Q_obs_H = Q_obs_H[0:len_mod]\n",
    "    fhv = 100 * np.nansum(Q_mod_H - Q_obs_H) / np.nansum(Q_obs_H)\n",
    "    return fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3152db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "qobs_def = qobs.values\n",
    "print(qsim_ensemble)\n",
    "\n",
    "fhv = FHV(qsim_ensemble, qobs_def, exceedance_prob=0.02)\n",
    "print(fhv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6869f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSE_LF(qsim_ensemble, qobs_def)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
